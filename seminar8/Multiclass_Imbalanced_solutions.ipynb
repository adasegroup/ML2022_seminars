{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/adasegroup/ML2021_seminars/blob/master/seminar8/Multiclass_Imbalanced_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced classification: Imbalanced and Multi-class cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this seminar we will learn how to perform classification in case of multiple balanced or imbalanced classes. \n",
    "\n",
    "The dataset, which we will use for this tutorial, is the smaller version [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/). The initial dataset consists from images of 120 breeds of dogs. In our case we are going to use just 4 classes out of those 120."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dogs_pic](https://dog.ceo/img/dog-api-fb.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The plan of the seminar:\n",
    "* a small introduction to Stanford Dogs Dataset\n",
    "* Producing the features of the images using the pretrained neural network (we will consider it as a black box)\n",
    "* Multi-class classification methods: One-vs-One and One-vs-Rest\n",
    "* Imbalanced dataset - why is it a problem?\n",
    "* Imbalanced classification methods: Over and Under-Sampling, SMOTE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start with some library imports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTES:\n",
    "* Class description\n",
    "* dataframe creation in class or in seminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: imbalanced-learn in /anaconda3/lib/python3.7/site-packages (0.7.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /anaconda3/lib/python3.7/site-packages (from imbalanced-learn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.23 in /anaconda3/lib/python3.7/site-packages (from imbalanced-learn) (0.24.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /anaconda3/lib/python3.7/site-packages (from imbalanced-learn) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /anaconda3/lib/python3.7/site-packages (from imbalanced-learn) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.23->imbalanced-learn) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/adasegroup/ML2021_seminars/raw/main/seminar8/data/dog_breeds.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open dog_breeds.zip, dog_breeds.zip.zip or dog_breeds.zip.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "!unzip -oqd \"./\" \"dog_breeds.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass_Imbalanced.ipynb           \u001b[34mdata\u001b[m\u001b[m\r\n",
      "Multiclass_Imbalanced_solutions.ipynb extra_theory.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./__MACOSX ./sample_data .config ./dog_breeds.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import sklearn\n",
    "import os.path\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you load your data from the local directory\n",
    "#################################\n",
    "#path_doggies =\"dog_breeds/small\"\n",
    "#paths_doggies = [path_doggies +'/'+ i for i in os.listdir(path_doggies) if '.DS_' not in i] \n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_doggies = [i for i in os.listdir('./') if '.DS_' not in i] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_show(img, ax, title = None):\n",
    "    \"\"\"\n",
    "    Plots the image on the particular axis\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img: Image,image to plot.\n",
    "    axis: matplotlib axis to plot on.\n",
    "    title: string, the title of the image\n",
    "    \n",
    "    \"\"\"\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    if title:\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: 'Multiclass_Imbalanced.ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f8c95c1398d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths_doggies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimg_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpaths_doggies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: 'Multiclass_Imbalanced.ipynb'"
     ]
    }
   ],
   "source": [
    "#images for plotting \n",
    "img_names = {}\n",
    "for num, i in enumerate(paths_doggies[:4]):\n",
    "    img_names.update({i.split('-')[-1]:paths_doggies[num]+'/'+os.listdir(i)[0]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the images from img_names\n",
    "fig, ax = plt.subplots(1,4, figsize=(20,10))\n",
    "k = 0\n",
    "for i, key in enumerate(img_names.keys()):\n",
    "    img_show(Image.open(img_names[key]), ax[i], title = key)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make working with the data much easier, we are going to create a class, that will store the ```image_to_features``` model, the ```data_list```, containing all the vectors of features of the image samples and the ```data_path```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogBreedDataset:\n",
    "    def __init__(self, data_path, feature_generator, num_samples=None):\n",
    "        \"\"\"\n",
    "        A wrapper class for Stanford Dog Breeds dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_path: string, the path to the dataset.\n",
    "        feature_generator: torch.nn.Module, the model, that receives the torch.tensor of the preprocessed image \n",
    "                           as the input and produces the tensor of features as the output.\n",
    "        num_samples: integer, the number of samples in each class to load, default: None.\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.model = feature_generator\n",
    "        self.num_samples = num_samples\n",
    "        self.data_list = []\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        \"\"\"\n",
    "        Opens and preprocesses an Image according to the requirements mentioned at https://pytorch.org/hub/pytorch_vision_vgg/\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path: the path to the image.\n",
    "        img_name: the name of the image file.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        input_tensor: the tensor of the preprocessed image.\n",
    "        input_batch: input_tensor with an extra dim, representing a batch\n",
    "        \"\"\"\n",
    "\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        input_tensor = preprocess(image)\n",
    "        input_batch = input_tensor.unsqueeze(0)\n",
    "        return input_batch\n",
    "\n",
    "    def load_dataset(self):\n",
    "        \"\"\"\n",
    "        Loads and preprocesses the images from the dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path: the path to the image.\n",
    "        img_name: the name of the image file.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        data_list: the list of vectors of features of dogs' images\n",
    "        \"\"\"\n",
    "        data_list = []\n",
    "        for path in tqdm(self.data_path):\n",
    "            counter = 0\n",
    "            for filename in tqdm(os.listdir(path)):\n",
    "                counter += 1\n",
    "                # input\n",
    "                with open(os.path.join(path, filename), 'rb') as file:\n",
    "                    batch = self.preprocess_image(Image.open(file))\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    features = self.model(batch).flatten().cpu().numpy()\n",
    "\n",
    "                # label\n",
    "                _, label = path.split('-', 1)\n",
    "                data_list.append((features, label))\n",
    "\n",
    "                if counter >= self.num_samples:\n",
    "                    break\n",
    "\n",
    "        return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model that we are going to use to get our features from this raw images is the Neural Network called **VGG-11** (you are going to learn about these types of NN models later in this course)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lucky for us, [```PyTorch```](https://pytorch.org) library stores some of the most popular [pretrained Neural Networks](https://pytorch.org/hub/), so we don't have to design and train the VGG-11 NN from sctratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dowbload the VGG11 model from pytorch hub\n",
    "model = torch.hub.load('pytorch/vision:v0.4.0', 'vgg11', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we do not need the whole network for producing the images' features - we will take only the part of it, just before the first __fully connected__ layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take only the \"head\" that outputs the images' features\n",
    "image_to_feats = model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_feats.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at our data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us download, preprocess and store the features of the images in a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_class = DogBreedDataset(paths_doggies, image_to_feats, num_samples = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = dataset_class.load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a pandas dataframe with all the features and labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#derive the list of labels from the paths_doggies list\n",
    "\n",
    "#take the data_list and after each list of features add the data label\n",
    "\n",
    "#create a list of column names\n",
    "\n",
    "#create a df_doggies dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, label = datalist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [f\"feat_{i+1}\" for i in range(len(features))]\n",
    "df_doggies = pd.DataFrame(\n",
    "    [feat for feat, lab in datalist],\n",
    "    columns=columns)\n",
    "\n",
    "df_doggies[\"y\"] = [lab for feat, lab in datalist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doggies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doggies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the labels to Categorical type and create the dictionary, in case we would like to recover the original labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doggies.y = pd.Categorical(df_doggies.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = dict(enumerate(df_doggies.y.cat.categories) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doggies.y = df_doggies.y.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data using dimensinonality reduction techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataPlotter is another blackbox that we are going to use for representing our features in a more convenient way for plotting (later in the course you will learn about PCA and TSNE).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class DataPlotter:\n",
    "    def __init__(self, data, dim_red = 'pca', X=None, y=None):\n",
    "        \"\"\"\n",
    "        A wrapper class for dimensionality reduction and plotting.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_path: dataframe, the dataset.\n",
    "        dim_red: string, the dimensionality reduction technique to use, either 'tsne' or 'pca'.\n",
    "        \"\"\" \n",
    "        self.data = data\n",
    "        self.dim_red = dim_red\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        if X is None:\n",
    "            self.X = self.data.loc[:, self.data.columns!='y']\n",
    "        if y is None:\n",
    "            self.y = self.data.y.astype(int)\n",
    "       \n",
    "    def shuffle_data(self):\n",
    "        \"\"\"\n",
    "        Randomly shuffling the data.\n",
    "        \"\"\"\n",
    "        self.X = self.X.sample(frac=1).reset_index(drop=True)\n",
    "        self.y = self.y.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    def reduce_dimension(self):\n",
    "        \"\"\"\n",
    "        Reduce the current dimension of the feature data to 2 dimensions using either pca or tsne.\n",
    "        \"\"\"\n",
    "        if self.dim_red =='tsne':\n",
    "            self.X_embedded = TSNE(n_components=2, perplexity=30.0).fit_transform(self.X)\n",
    "        elif self.dim_red == 'pca':\n",
    "            self.X_embedded = PCA(n_components=2).fit_transform(self.X)\n",
    "\n",
    "    def plot_data(self):\n",
    "        plt.figure(figsize=(20,10))\n",
    "        sns.scatterplot(self.X_embedded[:,0], self.X_embedded[:,1], hue = self.y, palette=\"rainbow\", s=100,  \n",
    "                        legend = \"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pltr = DataPlotter(df_doggies, dim_red = 'pca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pltr.reduce_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pltr.plot_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's try some multi-clall classification methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_doggies.y.astype(int)\n",
    "X = df_doggies.loc[:, df_doggies.columns!='y']\n",
    "\n",
    "split = train_test_split(X, y, test_size=0.5,\n",
    "                         random_state=42, stratify=y)\n",
    "train_X, test_X, train_y, test_y = split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the binary classification methods that you have already discussed in the previous seminars, unfortuntelly, only allow to distinguish one class from the other. However, in our case, we want to classify several dog breeds, so how can we do that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to this problem is using **One-vs-All** approach:\n",
    "![](https://miro.medium.com/max/1574/1*7sz-bpA4r_xSqAG3IJx-7w.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_SVC = LinearSVC(random_state=0)\n",
    "# model_LogReg = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "ovr_classifier = OneVsRestClassifier(clone(model_SVC), n_jobs=-1)\n",
    "ovr_classifier.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = ovr_classifier.predict(test_X)\n",
    "\n",
    "cmatrix = confusion_matrix(test_y, predict_y)\n",
    "pd.DataFrame(cmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rows -- fact\n",
    "columns -- predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy %.3f%%\" % (100 * ovr_classifier.score(test_X, test_y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-vs-One approach to multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ars.els-cdn.com/content/image/1-s2.0-S0950705116301459-gr1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "ovo_classifier = OneVsOneClassifier(clone(model_SVC))\n",
    "\n",
    "ovo_classifier.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = ovo_classifier.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy %.3f%%\" % (100 * ovo_classifier.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(test_y, predict_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data imbalance is a very common problem for many machine learning problems. Consider volcano erruption, or plane crush prediction - there is an abundance of negative examples, when the event does not happen and very little recorded cases of the events, the occurence of which we want to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where various methods of class balancing is going to help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_doggies_subset = df_doggies1.loc[df_doggies1.y.isin([0,1,2,3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub, y_sub = df_doggies.loc[:, df_doggies.columns!='y'], df_doggies.y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pltr = DataPlotter(df_doggies, dim_red = 'pca')\n",
    "data_pltr.reduce_dimension()\n",
    "data_pltr.plot_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print('Distribution before imbalancing: {}'.format(Counter(y_sub)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.datasets import make_imbalance\n",
    "X_res, y_res = make_imbalance(\n",
    "    X_sub, y_sub, sampling_strategy={0: 150, 1: 150, 2: 30, 3: 150},\n",
    "    random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distribution after imbalancing: {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pltr = DataPlotter(df_doggies, dim_red = 'pca', X = X_res, y = y_res)\n",
    "data_pltr.reduce_dimension()\n",
    "data_pltr.plot_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = train_test_split(X_res, y_res, test_size=0.3,\n",
    "                         random_state=42, stratify=y_res)\n",
    "train_X, test_X, train_y, test_y = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "model_SVC = LinearSVC(random_state=50)\n",
    "#model_SVC = RidgeClassifier(random_state=0)\n",
    "ovr_classifier = OneVsRestClassifier(clone(model_SVC), n_jobs=-1)\n",
    "ovr_classifier.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ovr_classifier.predict(test_X)\n",
    "#predictions = model_SVC.predict(test_X[test_y==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy %.3f%%\" % (100 * ovr_classifier.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(test_y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Techniques to try, when dealing with the imabalanced dataset:\n",
    "* Under/Over Sampling\n",
    "* Synthetic minority over-sampling technique and its variants (ADASYN, BorderlineSMOTE, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balancer = RandomUnderSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train_x, balanced_train_y = balancer.fit_resample(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distribution before balancing: {}'.format(Counter(train_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distribution after balancing: {}'.format(Counter(balanced_train_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(random_state=50, )\n",
    "ovr_classifier = OneVsRestClassifier(clone(model), n_jobs=-1)\n",
    "ovr_classifier.fit(balanced_train_x, balanced_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy %.3f%%\" % (100 * ovr_classifier.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ovr_classifier.predict(test_X)\n",
    "#predictions = model.predict(test_X[test_y==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(test_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(test_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balancer = RandomOverSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train_x, balanced_train_y = balancer.fit_resample(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distribution after balancing: {}'.format(Counter(balanced_train_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(random_state=50)\n",
    "ovr_classifier = OneVsRestClassifier(clone(model), n_jobs=-1)\n",
    "ovr_classifier.fit(balanced_train_x, balanced_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy %.3f%%\" % (100 * ovr_classifier.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ovr_classifier.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(test_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(test_y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ars.els-cdn.com/content/image/1-s2.0-S0950705119302898-gr1.jpg\" alt=\"smote\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebalancer = SMOTE(sampling_strategy='not majority', k_neighbors=5, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_balancer = RandomUnderSampler(sampling_strategy={0:20, 1: 30, 3:50}, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train_x, balanced_train_y = under_balancer.fit_resample(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Distribution before balancing: {}'.format(Counter(balanced_train_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(random_state=0)\n",
    "\n",
    "ovr_classifier = OneVsRestClassifier(clone(model))\n",
    "X_SMOTE, y_SMOTE = rebalancer.fit_resample(balanced_train_x, balanced_train_y)\n",
    "print('Distribution after balancing: {}'.format(Counter(y_SMOTE)))\n",
    "ovr_classifier = ovr_classifier.fit(X_SMOTE, y_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y_balanced = ovr_classifier.predict(test_X)\n",
    "pd.DataFrame(confusion_matrix(test_y, predict_y_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy %.3f%%\" % (100 * ovr_classifier.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(test_y, predict_y_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pltr = DataPlotter(df_doggies, dim_red = 'pca', X = X_SMOTE, y = y_SMOTE)\n",
    "data_pltr.reduce_dimension()\n",
    "data_pltr.plot_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different variations of SMOTE method, such as ADASYN, BalancedSMOTE etc. Many of them are avaliable in [```imblearn```](https://imbalanced-learn.readthedocs.io/en/stable/api.html) library.\n",
    "\n",
    "**Try out those methods yourself, using the mentioned methods, plot and analyze the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE, ADASYN, SVMSMOTE\n",
    "\n",
    "rebalancer_list = [BorderlineSMOTE(),ADASYN(n_neighbors = 3), SVMSMOTE()]\n",
    "model = LinearSVC(random_state=0)\n",
    "\n",
    "for rebalancer in rebalancer_list:\n",
    "    ovr_classifier = OneVsRestClassifier(clone(model))\n",
    "    X_SMOTE, y_SMOTE = rebalancer.fit_resample(train_X, train_y)\n",
    "    print('Distribution after balancing: {}'.format(Counter(y_SMOTE)))\n",
    "    ovr_classifier = ovr_classifier.fit(X_SMOTE, y_SMOTE)\n",
    "    predict_y_balanced = ovr_classifier.predict(test_X)\n",
    "    print(classification_report_imbalanced(test_y, predict_y_balanced))\n",
    "    data_pltr = DataPlotter(df_doggies, dim_red = 'pca', X = X_SMOTE, y = y_SMOTE)\n",
    "    data_pltr.reduce_dimension()\n",
    "    data_pltr.plot_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
